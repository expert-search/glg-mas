{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d17ec23",
   "metadata": {},
   "source": [
    "### NER Model Training\n",
    "This notebook contains all the training runs and hyperparameter tuning used to train the NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d088cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b553b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../GLG-Old Models, datasets/'\n",
    "df = pd.read_csv(PATH + 'ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "#df = df[:500000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3dcedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a8b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e09eb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8cd270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop('Tag',axis=1)\n",
    "#v = DictVectorizer(sparse=False)\n",
    "#X = v.fit_transform(X.to_dict('records'))\n",
    "#y = df['Tag']\n",
    "\n",
    "classes = list(np.unique(df['Tag']))\n",
    "\n",
    "#X_train, X_text, y_train, y_test = train_test_split(X, y, test_size=0.15,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c5c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a7dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0dccdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a58196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b70c5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X_p = list(np.array([sent2features(s) for s in sentences]).flatten())\n",
    "## y_p = list(np.array([sent2labels(s) for s in sentences]).flatten())\n",
    "## X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_p, y_p, test_size=0.1, random_state=4,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace8f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='l2sgd', all_possible_transitions=True, keep_tempfiles=None,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 08:54\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "#    algorithm='lbfgs',\n",
    "    algorithm='l2sgd',\n",
    "#    c1=0.1,\n",
    "#    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e218620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70af876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>I-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23974</th>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-per</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23975</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-per</td>\n",
       "      <td>I-per</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23976</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-tim</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23977</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-per</td>\n",
       "      <td>I-per</td>\n",
       "      <td>I-per</td>\n",
       "      <td>I-per</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23978</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23979 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9    \\\n",
       "0          O  B-geo  I-geo      O      O      O      O      O      O      O   \n",
       "1          O      O  B-gpe      O      O      O      O      O      O      O   \n",
       "2          O      O      O      O      O  B-gpe      O      O      O      O   \n",
       "3          O      O      O      O      O      O      O      O  B-geo      O   \n",
       "4          O      O      O      O      O  B-geo      O      O      O      O   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "23974      O  B-org  I-org      O      O  B-org      O      O      O  B-per   \n",
       "23975      O      O      O  B-per  I-per      O      O  B-geo      O      O   \n",
       "23976      O      O      O      O      O      O      O      O  B-tim      O   \n",
       "23977  B-gpe      O      O  B-per  I-per  I-per  I-per      O      O      O   \n",
       "23978      O      O      O      O      O      O      O      O      O      O   \n",
       "\n",
       "       ...   94    95    96    97    98    99    100   101   102   103  \n",
       "0      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "1      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "2      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "3      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "4      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "23974  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "23975  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "23976  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "23977  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "23978  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[23979 rows x 104 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0368eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.35      0.13      0.19       141\n",
      "       B-eve       0.61      0.42      0.50        98\n",
      "       B-geo       0.85      0.90      0.88     12313\n",
      "       B-gpe       0.97      0.94      0.96      5345\n",
      "       B-nat       0.51      0.43      0.47        53\n",
      "       B-org       0.80      0.74      0.77      6596\n",
      "       B-per       0.85      0.82      0.84      5642\n",
      "       B-tim       0.92      0.88      0.90      6638\n",
      "       I-art       0.09      0.03      0.04       106\n",
      "       I-eve       0.51      0.31      0.38        85\n",
      "       I-geo       0.80      0.79      0.79      2366\n",
      "       I-gpe       0.87      0.57      0.69        72\n",
      "       I-nat       0.64      0.37      0.47        19\n",
      "       I-org       0.81      0.80      0.80      5541\n",
      "       I-per       0.85      0.90      0.87      5741\n",
      "       I-tim       0.84      0.77      0.80      2150\n",
      "           O       0.99      0.99      0.99    293212\n",
      "\n",
      "    accuracy                           0.97    346118\n",
      "   macro avg       0.72      0.63      0.67    346118\n",
      "weighted avg       0.97      0.97      0.97    346118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test size = 0.33\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "020cda86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.35      0.13      0.19       141\n",
      "       B-eve       0.61      0.42      0.50        98\n",
      "       B-geo       0.85      0.90      0.88     12313\n",
      "       B-gpe       0.97      0.94      0.96      5345\n",
      "       B-nat       0.51      0.43      0.47        53\n",
      "       B-org       0.80      0.74      0.77      6596\n",
      "       B-per       0.85      0.82      0.84      5642\n",
      "       B-tim       0.92      0.88      0.90      6638\n",
      "       I-art       0.09      0.03      0.04       106\n",
      "       I-eve       0.51      0.31      0.38        85\n",
      "       I-geo       0.80      0.79      0.79      2366\n",
      "       I-gpe       0.87      0.57      0.69        72\n",
      "       I-nat       0.64      0.37      0.47        19\n",
      "       I-org       0.81      0.80      0.80      5541\n",
      "       I-per       0.85      0.90      0.87      5741\n",
      "       I-tim       0.84      0.77      0.80      2150\n",
      "\n",
      "   micro avg       0.86      0.85      0.85     52906\n",
      "   macro avg       0.70      0.61      0.65     52906\n",
      "weighted avg       0.85      0.85      0.85     52906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test size = 0.33\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde445dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.37      0.11      0.17       206\n",
      "       B-eve       0.49      0.39      0.43       145\n",
      "       B-geo       0.86      0.90      0.88     18698\n",
      "       B-gpe       0.97      0.94      0.95      8066\n",
      "       B-nat       0.52      0.49      0.51        85\n",
      "       B-org       0.79      0.73      0.76     10053\n",
      "       B-per       0.84      0.82      0.83      8531\n",
      "       B-tim       0.92      0.87      0.90     10083\n",
      "       I-art       0.16      0.04      0.06       157\n",
      "       I-eve       0.35      0.26      0.30       121\n",
      "       I-geo       0.80      0.80      0.80      3603\n",
      "       I-gpe       0.83      0.50      0.63       103\n",
      "       I-nat       0.55      0.48      0.51        25\n",
      "       I-org       0.80      0.78      0.79      8458\n",
      "       I-per       0.84      0.91      0.87      8655\n",
      "       I-tim       0.84      0.75      0.79      3256\n",
      "           O       0.99      0.99      0.99    444333\n",
      "\n",
      "    accuracy                           0.97    524578\n",
      "   macro avg       0.70      0.63      0.66    524578\n",
      "weighted avg       0.97      0.97      0.97    524578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Default, test_size = 0.5\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53720566",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'crf_ner_model.sav'\n",
    "pickle.dump(crf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b93d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       1.00      1.00      1.00       196\n",
      "       B-eve       1.00      1.00      1.00       163\n",
      "       B-geo       1.00      1.00      1.00     18946\n",
      "       B-gpe       1.00      1.00      1.00      7804\n",
      "       B-nat       1.00      1.00      1.00       116\n",
      "       B-org       1.00      1.00      1.00     10090\n",
      "       B-per       1.00      1.00      1.00      8459\n",
      "       B-tim       1.00      1.00      1.00     10250\n",
      "       I-art       1.00      1.00      1.00       140\n",
      "       I-eve       1.00      1.00      1.00       132\n",
      "       I-geo       1.00      1.00      1.00      3811\n",
      "       I-gpe       1.00      1.00      1.00        95\n",
      "       I-nat       1.00      1.00      1.00        26\n",
      "       I-org       1.00      1.00      1.00      8326\n",
      "       I-per       1.00      1.00      1.00      8596\n",
      "       I-tim       1.00      1.00      1.00      3272\n",
      "           O       1.00      1.00      1.00    443575\n",
      "\n",
      "    accuracy                           1.00    523997\n",
      "   macro avg       1.00      1.00      1.00    523997\n",
      "weighted avg       1.00      1.00      1.00    523997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df1f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.02      0.04       206\n",
      "       B-eve       0.62      0.36      0.45       145\n",
      "       B-geo       0.86      0.89      0.88     18698\n",
      "       B-gpe       0.96      0.93      0.95      8066\n",
      "       B-nat       0.66      0.32      0.43        85\n",
      "       B-org       0.78      0.74      0.76     10053\n",
      "       B-per       0.84      0.81      0.82      8531\n",
      "       B-tim       0.93      0.85      0.89     10083\n",
      "       I-art       0.67      0.01      0.03       157\n",
      "       I-eve       0.50      0.21      0.30       121\n",
      "       I-geo       0.84      0.76      0.79      3603\n",
      "       I-gpe       0.92      0.47      0.62       103\n",
      "       I-nat       0.75      0.24      0.36        25\n",
      "       I-org       0.78      0.80      0.79      8458\n",
      "       I-per       0.83      0.92      0.87      8655\n",
      "       I-tim       0.84      0.74      0.79      3256\n",
      "           O       0.99      0.99      0.99    444333\n",
      "\n",
      "    accuracy                           0.97    524578\n",
      "   macro avg       0.78      0.59      0.63    524578\n",
      "weighted avg       0.97      0.97      0.97    524578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD, test_size = 0.5\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd495c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.06      0.11        49\n",
      "       B-eve       0.50      0.35      0.41        23\n",
      "       B-geo       0.85      0.92      0.88      3775\n",
      "       B-gpe       0.97      0.94      0.96      1673\n",
      "       B-nat       0.62      0.29      0.40        17\n",
      "       B-org       0.82      0.73      0.77      1961\n",
      "       B-per       0.84      0.82      0.83      1682\n",
      "       B-tim       0.93      0.88      0.91      1978\n",
      "       I-art       0.40      0.11      0.17        37\n",
      "       I-eve       0.42      0.22      0.29        23\n",
      "       I-geo       0.80      0.79      0.80       706\n",
      "       I-gpe       0.95      0.55      0.69        33\n",
      "       I-nat       0.67      0.40      0.50         5\n",
      "       I-org       0.83      0.80      0.81      1641\n",
      "       I-per       0.84      0.93      0.88      1710\n",
      "       I-tim       0.84      0.78      0.81       622\n",
      "           O       0.99      0.99      0.99     89109\n",
      "\n",
      "    accuracy                           0.97    105044\n",
      "   macro avg       0.75      0.62      0.66    105044\n",
      "weighted avg       0.97      0.97      0.97    105044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c0b695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.06      0.11        49\n",
      "       B-eve       0.50      0.35      0.41        23\n",
      "       B-geo       0.85      0.92      0.88      3775\n",
      "       B-gpe       0.97      0.94      0.96      1673\n",
      "       B-nat       0.62      0.29      0.40        17\n",
      "       B-org       0.82      0.73      0.77      1961\n",
      "       B-per       0.84      0.82      0.83      1682\n",
      "       B-tim       0.93      0.88      0.91      1978\n",
      "       I-art       0.40      0.11      0.17        37\n",
      "       I-eve       0.42      0.22      0.29        23\n",
      "       I-geo       0.80      0.79      0.80       706\n",
      "       I-gpe       0.95      0.55      0.69        33\n",
      "       I-nat       0.67      0.40      0.50         5\n",
      "       I-org       0.83      0.80      0.81      1641\n",
      "       I-per       0.84      0.93      0.88      1710\n",
      "       I-tim       0.84      0.78      0.81       622\n",
      "\n",
      "   micro avg       0.86      0.85      0.86     15935\n",
      "   macro avg       0.74      0.60      0.64     15935\n",
      "weighted avg       0.86      0.85      0.85     15935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cc799c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.40      0.12      0.19        49\n",
      "       B-eve       0.60      0.39      0.47        23\n",
      "       B-geo       0.86      0.91      0.88      3775\n",
      "       B-gpe       0.97      0.95      0.96      1673\n",
      "       B-nat       0.64      0.41      0.50        17\n",
      "       B-org       0.81      0.74      0.78      1961\n",
      "       B-per       0.86      0.84      0.85      1682\n",
      "       B-tim       0.93      0.88      0.91      1978\n",
      "       I-art       0.50      0.11      0.18        37\n",
      "       I-eve       0.56      0.22      0.31        23\n",
      "       I-geo       0.79      0.81      0.80       706\n",
      "       I-gpe       0.90      0.55      0.68        33\n",
      "       I-nat       0.40      0.40      0.40         5\n",
      "       I-org       0.82      0.79      0.81      1641\n",
      "       I-per       0.86      0.91      0.88      1710\n",
      "       I-tim       0.84      0.78      0.81       622\n",
      "\n",
      "   micro avg       0.87      0.85      0.86     15935\n",
      "   macro avg       0.73      0.61      0.65     15935\n",
      "weighted avg       0.86      0.85      0.86     15935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fd298bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.40      0.12      0.19        49\n",
      "       B-eve       0.60      0.39      0.47        23\n",
      "       B-geo       0.86      0.91      0.88      3775\n",
      "       B-gpe       0.97      0.95      0.96      1673\n",
      "       B-nat       0.64      0.41      0.50        17\n",
      "       B-org       0.81      0.74      0.78      1961\n",
      "       B-per       0.86      0.84      0.85      1682\n",
      "       B-tim       0.93      0.88      0.91      1978\n",
      "       I-art       0.50      0.11      0.18        37\n",
      "       I-eve       0.56      0.22      0.31        23\n",
      "       I-geo       0.79      0.81      0.80       706\n",
      "       I-gpe       0.90      0.55      0.68        33\n",
      "       I-nat       0.40      0.40      0.40         5\n",
      "       I-org       0.82      0.79      0.81      1641\n",
      "       I-per       0.86      0.91      0.88      1710\n",
      "       I-tim       0.84      0.78      0.81       622\n",
      "           O       0.99      0.99      0.99     89109\n",
      "\n",
      "    accuracy                           0.97    105044\n",
      "   macro avg       0.75      0.64      0.67    105044\n",
      "weighted avg       0.97      0.97      0.97    105044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa541d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fergu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.22      0.08      0.12        25\n",
      "       B-eve       0.70      0.40      0.51        40\n",
      "       B-geo       0.87      0.91      0.89      2716\n",
      "       B-gpe       0.97      0.93      0.95      1180\n",
      "       B-nat       0.58      0.50      0.54        14\n",
      "       B-org       0.79      0.75      0.77      1338\n",
      "       B-per       0.84      0.82      0.83      1203\n",
      "       B-tim       0.92      0.87      0.89      1425\n",
      "       I-art       0.00      0.00      0.00        20\n",
      "       I-eve       0.57      0.43      0.49        30\n",
      "       I-geo       0.84      0.76      0.80       548\n",
      "       I-gpe       0.75      0.35      0.48        17\n",
      "       I-nat       1.00      0.25      0.40         8\n",
      "       I-org       0.79      0.77      0.78      1062\n",
      "       I-per       0.84      0.88      0.86      1225\n",
      "       I-tim       0.84      0.73      0.78       470\n",
      "           O       0.99      0.99      0.99     63882\n",
      "\n",
      "    accuracy                           0.97     75203\n",
      "   macro avg       0.73      0.61      0.65     75203\n",
      "weighted avg       0.97      0.97      0.97     75203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fed44bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.33      0.40         6\n",
      "       B-eve       0.60      0.38      0.46         8\n",
      "       B-geo       0.72      0.78      0.75       225\n",
      "       B-gpe       0.81      0.81      0.81       146\n",
      "       B-nat       0.00      0.00      0.00         2\n",
      "       B-org       0.63      0.56      0.59       149\n",
      "       B-per       0.83      0.86      0.85       115\n",
      "       B-tim       0.90      0.79      0.84       121\n",
      "       I-art       0.00      0.00      0.00         1\n",
      "       I-eve       0.50      0.33      0.40         6\n",
      "       I-geo       0.65      0.47      0.55        55\n",
      "       I-gpe       0.00      0.00      0.00         4\n",
      "       I-org       0.79      0.60      0.68       147\n",
      "       I-per       0.86      0.96      0.90       137\n",
      "       I-tim       0.63      0.66      0.64        29\n",
      "           O       0.99      0.99      0.99      6546\n",
      "\n",
      "    accuracy                           0.95      7697\n",
      "   macro avg       0.59      0.53      0.55      7697\n",
      "weighted avg       0.95      0.95      0.95      7697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))#, labels = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da51c0e",
   "metadata": {},
   "source": [
    "### Predict on Some Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0a5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prep_query(phrase):\n",
    "    split_query = re.findall(r\"[\\w']+|[.,!?;]\", phrase)\n",
    "    \n",
    "    pos_tags = pos_tag(split_query)\n",
    "    \n",
    "    df_query = pd.DataFrame({'Sentence #':['Sentence: 1'] * len(pos_tags),\n",
    "                            'Word':[pair[0] for pair in pos_tags],\n",
    "                            'POS':[pair[1] for pair in pos_tags],\n",
    "                            'Tag':[None] * len(pos_tags)})\n",
    "       \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea72db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Donald Trump is a former host on The Apprentice. He is an American businessman and former President.\"\n",
    "s = 'hello how are you'\n",
    "s = 'The Second World War started in 1914 and ended in 1918'\n",
    "s = 'The Korean War started in 1939 and ended in 1945'\n",
    "s = 'Iraq and Iran were once at war. Saddam Hussein was involved'\n",
    "s = 'The World Cup is a quadrennial sporting event. FIFA is the governing body involved.'\n",
    "\n",
    "\n",
    "x = prep_query(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f25ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'The'),\n",
       " ('B-org', 'World'),\n",
       " ('I-org', 'Cup'),\n",
       " ('O', 'is'),\n",
       " ('O', 'a'),\n",
       " ('O', 'quadrennial'),\n",
       " ('O', 'sporting'),\n",
       " ('O', 'event'),\n",
       " ('O', '.'),\n",
       " ('B-org', 'FIFA'),\n",
       " ('O', 'is'),\n",
       " ('O', 'the'),\n",
       " ('O', 'governing'),\n",
       " ('O', 'body'),\n",
       " ('O', 'involved'),\n",
       " ('O', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getter_query = SentenceGetter(x)\n",
    "sentences_query = getter_query.sentences\n",
    "\n",
    "X_query = [sent2features(s) for s in sentences_query]\n",
    "X_words = [s[0] for s in sentences_query[0]]\n",
    "\n",
    "pred = crf.predict(X_query)\n",
    "\n",
    "list(zip(pred[0],X_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf44b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
